import pandas as pd
import time
import csv
import os
from collections import Counter
import boto3

# =============================
# ğŸ”§ ì„¤ì •
# =============================
S3_BUCKET = "bookreview-results"
S3_KEY = "cleaned/cleaned_books_100.csv"
LOCAL_FILE = "temp_100.csv"
OUTPUT_FILE = "benchmark_metrics_sequential.csv"
LOADS = [25, 50, 75, 100]  # ë°ì´í„° ë¹„ìœ¨ (%)

# =============================
# ğŸ“¥ S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
# =============================
def download_from_s3():
    print("\nğŸ“¥ Downloading data from S3...")
    s3 = boto3.client("s3")
    s3.download_file(S3_BUCKET, S3_KEY, LOCAL_FILE)
    print("âœ… complete  Download")

# =============================
# ğŸ”  ì›Œë“œì¹´ìš´íŠ¸ í•¨ìˆ˜ (ìˆœì°¨ì  ì²˜ë¦¬)
# =============================
def word_count(texts):
    counter = Counter()
    for text in texts:
        if isinstance(text, str):
            words = text.lower().split()
            counter.update(words)
    return counter

# =============================
# ğŸ˜Š ê°ì • ë¶„ì„ ì¹´ìš´íŠ¸ í•¨ìˆ˜ (ìˆœì°¨ì  ì²˜ë¦¬)
# =============================
def sentiment_count(sentiments):
    counter = Counter()
    for s in sentiments:
        if isinstance(s, str):
            counter[s.lower()] += 1
    return counter

# =============================
# ğŸ ì‹¤í–‰
# =============================
def run_sequential_tasks():
    download_from_s3()
    df = pd.read_csv(LOCAL_FILE)
    total_rows = len(df)

    results = []

    for pct in LOADS:
        subset = df.iloc[: total_rows * pct // 100]

        # --- ì›Œë“œì¹´ìš´íŠ¸ ---
        texts = subset["cleaned_text"].tolist()
        print(f"\nğŸš€ Sequential WordCount start ({pct}%)")
        start = time.time()
        word_counter = word_count(texts)
        end = time.time()
        elapsed = end - start
        throughput = len(texts) / elapsed
        latency = elapsed / len(texts)
        
        print("=========================================")
        print(f"1. Processing Time: {elapsed:.4f} sec")
        print(f"2. Throughput: {throughput:.2f} records/sec")
        print(f"3. Latency: {latency:.6f} sec/record")

        results.append({
            "type": "sequential",
            "task": "wordcount",
            "percent": pct,
            "records": len(texts),
            "time_sec": round(elapsed, 4),
            "throughput_rps": round(throughput, 2),
            "latency_spr": round(latency, 6)
        })

        # --- ê°ì • ë¶„ì„ ---
        sentiments = subset["sentiment"].tolist()
        print(f"\nğŸš€ Sequential Sentiment start ({pct}%)")
        start = time.time()
        sentiment_counter = sentiment_count(sentiments)
        end = time.time()
        elapsed = end - start
        throughput = len(sentiments) / elapsed
        latency = max(elapsed / len(sentiments), 1e-6)
        
        print("=========================================")
        print(f"1. Processing Time: {elapsed:.4f} sec")
        print(f"2. Throughput: {throughput:.2f} records/sec")
        print(f"3. Latency: {latency:.6f} sec/record")

        results.append({
            "type": "sequential",
            "task": "sentiment",
            "percent": pct,
            "records": len(sentiments),
            "time_sec": round(elapsed, 4),
            "throughput_rps": round(throughput, 2),
            "latency_spr": round(latency, 6)
        })

    # ê²°ê³¼ CSV ì €ì¥
    with open(OUTPUT_FILE, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=results[0].keys())
        writer.writeheader()
        writer.writerows(results)

    print(f"\nâœ… complete: {OUTPUT_FILE}")

    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
    if os.path.exists(LOCAL_FILE):
        os.remove(LOCAL_FILE)
        #print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ {LOCAL_FILE} ì‚­ì œ ì™„ë£Œ.")

def upload_to_s3(local_file, bucket, s3_key):
    s3 = boto3.client("s3")
    try:
        s3.upload_file(local_file, bucket, s3_key)
        print(f"âœ… Uploaded {local_file} to s3://{bucket}/{s3_key}")
    except Exception as e:
        print(f"âŒ Failed to upload to S3: {e}")

if __name__ == "__main__":
    run_sequential_tasks()
    upload_to_s3("benchmark_metrics_sequential.csv", "bookreview-results", "hybrid/benchmark_metrics_sequential.csv")
