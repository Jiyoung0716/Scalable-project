import pandas as pd
import time
import csv
import os
from collections import Counter
import boto3


S3_BUCKET = "bookreview-results"
S3_KEY = "cleaned/cleaned_books_100.csv"
LOCAL_FILE = "temp_100.csv"
OUTPUT_FILE = "benchmark_metrics_sequential.csv"
LOADS = [25, 50, 75, 100]  # Îç∞Ïù¥ÌÑ∞ ÎπÑÏú® (%)


def download_from_s3():
    print("\nüì• Downloading data from S3...")
    s3 = boto3.client("s3")
    s3.download_file(S3_BUCKET, S3_KEY, LOCAL_FILE)
    print("‚úÖ complete  Download")


def word_count(texts):
    counter = Counter()
    for text in texts:
        if isinstance(text, str):
            words = text.lower().split()
            counter.update(words)
    return counter


def sentiment_count(sentiments):
    counter = Counter()
    for s in sentiments:
        if isinstance(s, str):
            counter[s.lower()] += 1
    return counter


def run_sequential_tasks():
    download_from_s3()
    df = pd.read_csv(LOCAL_FILE)
    total_rows = len(df)

    results = []

    for pct in LOADS:
        subset = df.iloc[: total_rows * pct // 100]

        # --- ÏõåÎìúÏπ¥Ïö¥Ìä∏ ---
        texts = subset["cleaned_text"].tolist()
        print(f"\nüöÄ Sequential WordCount start ({pct}%)")
        start = time.time()
        word_counter = word_count(texts)
        end = time.time()
        elapsed = end - start
        throughput = len(texts) / elapsed
        latency = elapsed / len(texts)
        
        print("=========================================")
        print(f"1. Processing Time: {elapsed:.4f} sec")
        print(f"2. Throughput: {throughput:.2f} records/sec")
        print(f"3. Latency: {latency:.6f} sec/record")

        results.append({
            "type": "sequential",
            "task": "wordcount",
            "percent": pct,
            "records": len(texts),
            "time_sec": round(elapsed, 4),
            "throughput_rps": round(throughput, 2),
            "latency_spr": round(latency, 6)
        })

        # --- Í∞êÏ†ï Î∂ÑÏÑù ---
        sentiments = subset["sentiment"].tolist()
        print(f"\nüöÄ Sequential Sentiment start ({pct}%)")
        start = time.time()
        sentiment_counter = sentiment_count(sentiments)
        end = time.time()
        elapsed = end - start
        throughput = len(sentiments) / elapsed
        latency = max(elapsed / len(sentiments), 1e-6)
        
        print("=========================================")
        print(f"1. Processing Time: {elapsed:.4f} sec")
        print(f"2. Throughput: {throughput:.2f} records/sec")
        print(f"3. Latency: {latency:.6f} sec/record")

        results.append({
            "type": "sequential",
            "task": "sentiment",
            "percent": pct,
            "records": len(sentiments),
            "time_sec": round(elapsed, 4),
            "throughput_rps": round(throughput, 2),
            "latency_spr": round(latency, 6)
        })

    # Í≤∞Í≥º CSV Ï†ÄÏû•
    with open(OUTPUT_FILE, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=results[0].keys())
        writer.writeheader()
        writer.writerows(results)

    print(f"\n‚úÖ complete: {OUTPUT_FILE}")

    # ÏûÑÏãú ÌååÏùº ÏÇ≠Ï†ú
    if os.path.exists(LOCAL_FILE):
        os.remove(LOCAL_FILE)

def upload_to_s3(local_file, bucket, s3_key):
    s3 = boto3.client("s3")
    try:
        s3.upload_file(local_file, bucket, s3_key)
        print(f"‚úÖ Uploaded {local_file} to s3://{bucket}/{s3_key}")
    except Exception as e:
        print(f"‚ùå Failed to upload to S3: {e}")

if __name__ == "__main__":
    run_sequential_tasks()
    upload_to_s3("benchmark_metrics_sequential.csv", "bookreview-results", "hybrid/benchmark_metrics_sequential.csv")
